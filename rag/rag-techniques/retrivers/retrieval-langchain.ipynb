{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNnyl+8CtTDhtNzR66npuoL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MmSUmzlOpN4f","executionInfo":{"status":"ok","timestamp":1743097558230,"user_tz":-60,"elapsed":11237,"user":{"displayName":"Jaime GÃ³mez Moraleda","userId":"01073662164120725208"}},"outputId":"b52216e0-dc96-4550-bd6d-190a3686ab11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully loaded 1 document(s) from text-example.txt\n","Split text into 3 chunks.\n","Chroma vector store created.\n","RetrievalQA chain created.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"]},{"output_type":"stream","name":"stdout","text":["\n","Query Result:\n","{'query': 'What is this document about?', 'result': ' The document is about the landscape of Artificial Intelligence (AI), with a focus on Large Language Models (LLMs) and AI agents. It discusses the limitations of LLMs and the role of AI agents in addressing those limitations. It also mentions the use of LangChain, an open-source framework, in building LLM-powered applications and the potential applications of AI agents in various domains. '}\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"]},{"output_type":"stream","name":"stdout","text":["\n","Relevant Document Metadata:\n","{'source': 'text-example.txt'}\n"]}],"source":["!pip install -q langchain openai chromadb langchain-community langchain-openai tiktoken\n","\n","from google.colab import userdata\n","from langchain_openai import OpenAIEmbeddings, OpenAI\n","from langchain_community.vectorstores import Chroma\n","from langchain.chains import RetrievalQA\n","from langchain.document_loaders import TextLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# 1. Setting up OpenAI API Key:\n","OPENAI_API_KEY = userdata.get(\"OpenAI-key\")\n","\n","# 2. Loading Text Documents:\n","text_file_path = \"text-example.txt\"\n","try:\n","    loader = TextLoader(text_file_path)\n","    documents = loader.load()\n","    print(f\"Successfully loaded {len(documents)} document(s) from {text_file_path}\")\n","except FileNotFoundError:\n","    print(f\"Error: Text file '{text_file_path}' not found.\")\n","    documents = []\n","\n","# 3. Splitting Documents:\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","texts = text_splitter.split_documents(documents)\n","print(f\"Split text into {len(texts)} chunks.\")\n","\n","# 4. Creating Embeddings:\n","try:\n","    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n","except Exception as e:\n","    print(f\"Error creating embeddings: {e}. Please ensure your OpenAI API key is correctly set.\")\n","    embeddings = None\n","\n","# 5. Creating Vector Store:\n","if embeddings:\n","    db = Chroma.from_documents(texts, embeddings)\n","    print(\"Chroma vector store created.\")\n","else:\n","    db = None\n","    print(\"Vector store creation skipped due to embedding error.\")\n","\n","# 6. Creating Retrieval QA Chain:\n","if db:\n","    try:\n","        qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(openai_api_key=OPENAI_API_KEY), chain_type=\"stuff\", retriever=db.as_retriever())\n","        print(\"RetrievalQA chain created.\")\n","    except Exception as e:\n","        print(f\"Error creating RetrievalQA chain: {e}\")\n","        qa_chain = None\n","else:\n","    qa_chain = None\n","    print(\"RetrievalQA chain creation skipped due to vector store error.\")\n","\n","# 7. Query the Chain:\n","if qa_chain:\n","    query = \"What is this document about?\"\n","    result = qa_chain.invoke(query) # change run to invoke.\n","    print(\"\\nQuery Result:\")\n","    print(result)\n","else:\n","    print(\"\\nQuery skipped due to RetrievalQA chain error.\")\n","\n","# 8. Use Metadata:\n","if db:\n","    retriever = db.as_retriever()\n","    relevant_documents = retriever.invoke(query) # change get_relevant_documents to invoke.\n","    if relevant_documents:\n","        print(\"\\nRelevant Document Metadata:\")\n","        print(relevant_documents[0].metadata)\n","    else:\n","        print(\"\\nNo relevant documents found.\")\n","else:\n","  print(\"\\nMetadata retrieval skipped due to vector store error.\")"]}]}